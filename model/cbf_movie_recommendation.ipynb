{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d018d4f0",
   "metadata": {},
   "source": [
    "# Movie Recommendation Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de41d3e",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77125708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from ast import literal_eval # For safely converting stringified lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e8cc94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223195</td>\n",
       "      <td>The Making of a Legend: Gone with the Wind</td>\n",
       "      <td>documentary</td>\n",
       "      <td>cinemahistory, makingof, moviebusiness, behind...</td>\n",
       "      <td>This documentary revisits the making of Gone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49343</td>\n",
       "      <td>Dream Demon</td>\n",
       "      <td>horror</td>\n",
       "      <td>london, dreamdemon, bride-to-be, mirror, dream...</td>\n",
       "      <td>As her marriage to decorated war hero Oliver d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                       title       genres  \\\n",
       "0    223195  The Making of a Legend: Gone with the Wind  documentary   \n",
       "1     49343                                 Dream Demon       horror   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  cinemahistory, makingof, moviebusiness, behind...   \n",
       "1  london, dreamdemon, bride-to-be, mirror, dream...   \n",
       "\n",
       "                                            overview  \n",
       "0  This documentary revisits the making of Gone w...  \n",
       "1  As her marriage to decorated war hero Oliver d...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH  = \"D:/Github_ThisPC/TMDB_RecoFlow/airflow/data/cbf_movie.parquet\"\n",
    "\n",
    "df = pd.read_parquet(DATASET_PATH)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41d92a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135886 entries, 0 to 135885\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   movie_id  135886 non-null  int64 \n",
      " 1   title     135886 non-null  object\n",
      " 2   genres    135886 non-null  object\n",
      " 3   keywords  135886 non-null  object\n",
      " 4   overview  135886 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40fd09c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135886, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "812822c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movie_id', 'title', 'genres', 'keywords', 'overview'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d5134",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bfe5069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id    0\n",
       "title       0\n",
       "genres      0\n",
       "keywords    0\n",
       "overview    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4069eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of duplicate rows\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e44f51c",
   "metadata": {},
   "source": [
    "Download necessary NLTK data\n",
    "The code ensures that all required resources from the NLTK library are available for text processing. This is often necessary when working with stopwords or lemmatization. The resources are downloaded only if they are not already available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "391362bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary NLTK data (only need to do this once)\n",
    "try:\n",
    "    stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "try:\n",
    "    WordNetLemmatizer().lemmatize('test')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "# Download WordNet if not already available\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet.zip')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fceafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions\n",
    "stop_words = set(stopwords.words('english'))  # Define stop words for text processing\n",
    "lemmatizer = WordNetLemmatizer()  # Initialize lemmatizer for stemming words to their root form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52114eb5",
   "metadata": {},
   "source": [
    "Text Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d93d3548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"Remove stopwords from a given text.\"\"\"\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        words = [word for word in text.split() if word.lower() not in stop_words]\n",
    "        return \" \".join(words)  # Join words back into a string\n",
    "    return \"\"\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"Lemmatize the words in a given text.\"\"\"\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        words = [lemmatizer.lemmatize(word) for word in text.split()]\n",
    "        return \" \".join(words)  # Join lemmatized words back into a string\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb87d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(set1, set2):\n",
    "    \"\"\"Calculate Jaccard similarity between two sets.\"\"\"\n",
    "    intersection = len(set1.intersection(set2))  # Size of intersection\n",
    "    union = len(set1.union(set2))  # Size of union\n",
    "    return intersection / union if union != 0 else 0  # Avoid division by zero "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54252ba2",
   "metadata": {},
   "source": [
    "The safe_literal_eval function safely evaluates strings that may represent data structures like lists, tuples, or dictionaries. If the value is a string, it attempts to parse it using literal_eval, and if that fails, it splits the string by commas into a list. If the value is None or NaN, it returns an empty list. For other types of input, the function simply returns the value as-is. The function is applied to the keywords and genres columns of a DataFrame, ensuring that string representations of lists or similar structures are properly converted into Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a1480b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "\n",
    "def safe_literal_eval(value):\n",
    "    \"\"\"Safely evaluate a string to its literal representation.\"\"\"\n",
    "    if isinstance(value, str):  # Check if it's a string\n",
    "        try:\n",
    "            # Try to evaluate the string as a literal (e.g., list, tuple, dict)\n",
    "            return literal_eval(value)\n",
    "        except (ValueError, SyntaxError):\n",
    "            # If evaluation fails, return the string as a list by splitting on commas\n",
    "            return value.split(',') if value else []\n",
    "    elif isinstance(value, float) and np.isnan(value):  # Handle NaN values\n",
    "        return []  # Return an empty list for NaN values\n",
    "    elif value is None:  # Handle None explicitly\n",
    "        return []  # Return an empty list for None\n",
    "    else:\n",
    "        return value  # Return the value as-is if it's already in the correct format\n",
    "\n",
    "# Apply the function to the specified columns\n",
    "features = ['keywords', 'genres']\n",
    "for feature in features:\n",
    "    df[feature] = df[feature].apply(safe_literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a4498",
   "metadata": {},
   "source": [
    "It first limits the data to the first 25,000 (RAM issue) rows for efficiency and fills missing values in the overview and keywords columns with empty strings. Then, it uses TF-IDF vectorization on the overviews and CountVectorizer on the keywords (after ensuring the keywords are properly formatted as strings). Cosine similarity is computed for both overviews and keywords to measure similarity between movies. This setup allows for the creation of a recommendation system by comparing movies based on either their content or their keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b270708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert all strings to lower case and strip names of spaces\n",
    "def clean_data(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    else:\n",
    "        return ''\n",
    "        \n",
    "\n",
    "# Apply clean_data function to your features.\n",
    "features = ['keywords', 'genres']\n",
    "\n",
    "for feature in features:\n",
    "    df[feature] = df[feature].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "037e3ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== For Only Testing =====\n",
    "recommended_titles = [\n",
    "    \"The Dark Knight Rises\",\n",
    "    \"The Dark Knight\",\n",
    "    \"Batman Begins\",\n",
    "    \"Batman: The Long Halloween, Part One\",\n",
    "    \"Batman: The Long Halloween, Part Two\",\n",
    "    \"Batman vs. Two-Face\",\n",
    "    \"The Siege\",\n",
    "    \"The Batman\",\n",
    "    \"Class of 1984\",\n",
    "    \"The Negotiator\",\n",
    "    \"Double Impact\"\n",
    "]\n",
    "df_recommendations = df[df[\"title\"].isin(recommended_titles)]\n",
    "df = df[:25000] # Filter first 25000\n",
    "df = pd.concat([df_recommendations, df]).drop_duplicates(subset=[\"movie_id\"])\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you already have 'df' as your DataFrame\n",
    "# Handle missing values in overview and keywords columns\n",
    "df['overview'] = df['overview'].fillna('')  # Replace NaN in overview\n",
    "df['keywords'] = df['keywords'].fillna('')  # Replace NaN in keywords\n",
    "\n",
    "df = df.sort_values(\"title\").reset_index(drop=True)\n",
    "\n",
    "# Feature Extraction\n",
    "# Create TF-IDF matrix for movie overviews\n",
    "tfidf_overview = TfidfVectorizer(stop_words='english')\n",
    "tfidf_overview_matrix = tfidf_overview.fit_transform(df['overview'])\n",
    "\n",
    "# Convert keywords into strings (if they are lists) and create a TF-IDF matrix for keywords\n",
    "# Ensure keywords are properly joined into a string for vectorization\n",
    "keywords_ = [' '.join(keywords) if isinstance(keywords, list) else keywords for keywords in df['keywords']]\n",
    "vector = CountVectorizer(stop_words='english')\n",
    "vector_keywords_matrix = vector.fit_transform(keywords_)\n",
    "\n",
    "# Extract genres and titles as lists for similarity computation\n",
    "movie_genres = df['genres'].tolist()\n",
    "movie_titles = df['title'].tolist()\n",
    "movie_ids = df['movie_id'].tolist()\n",
    "\n",
    "# Calculate cosine similarity for both overview and keywords\n",
    "cosine_sim_overview = cosine_similarity(tfidf_overview_matrix)\n",
    "cosine_sim_keywords = cosine_similarity(vector_keywords_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96d2532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_similarity(movie1_index, movie2_index, genre_weight=0.2, overview_weight=0.5, keyword_weight=0.3):\n",
    "    \"\"\"\n",
    "    Combine similarity scores from genres, overview, and keywords with adjustable weights.\n",
    "    \"\"\"\n",
    "    genre_sim = jaccard_similarity(set(movie_genres[movie1_index]), set(movie_genres[movie2_index]))  # Jaccard similarity for genres\n",
    "    overview_sim = cosine_sim_overview[movie1_index, movie2_index]  # Cosine similarity for overviews\n",
    "    keyword_sim = cosine_sim_keywords[movie1_index, movie2_index]  # Cosine similarity for keywords\n",
    "    return (genre_weight * genre_sim) + (overview_weight * overview_sim) + (keyword_weight * keyword_sim)  # Weighted sum of similarities\n",
    "\n",
    "\n",
    "def get_recommendations_by_title(movie_title, top_n=10):\n",
    "    \"\"\"\n",
    "    Get top N recommendations for a given movie title based on combined similarity scores.\n",
    "    Warns if the title appears more than once in the dataset.\n",
    "    \"\"\"\n",
    "    # Check if the input is a string\n",
    "    if not isinstance(movie_title, str):\n",
    "        return \"Error: Movie title must be a string.\"\n",
    "\n",
    "    # Count how many times the title appears\n",
    "    matching_indices = [i for i, title in enumerate(movie_titles) if title == movie_title]\n",
    "\n",
    "    if not matching_indices:\n",
    "        return f\"Error: '{movie_title}' not found in the dataset.\"\n",
    "\n",
    "    if len(matching_indices) > 1:\n",
    "        print(f\"⚠️ Warning: The title '{movie_title}' appears {len(matching_indices)} times. Using the first occurrence.\")\n",
    "\n",
    "    movie_index = matching_indices[0]\n",
    "\n",
    "    # Calculate similarity for all other movies\n",
    "    similarities = [\n",
    "        (i, combined_similarity(movie_index, i))\n",
    "        for i in range(len(movie_titles)) if i != movie_index\n",
    "    ]\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(f\"\\nRecommendations for '{movie_title}' (index: {movie_index}):\")\n",
    "    for i, (idx, sim) in enumerate(similarities[:top_n], 1):\n",
    "        print(f\"{i}. Movie: {movie_titles[idx]} (ID: {movie_ids[idx]}), Similarity: {sim:.4f}\")\n",
    "\n",
    "\n",
    "def get_recommendations_by_id(input_id, top_n=10):\n",
    "    \"\"\"\n",
    "    Get top N recommendations for a given movie ID based on combined similarity scores.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to convert the input to integer\n",
    "        movie_id = int(input_id)\n",
    "    except (ValueError, TypeError):\n",
    "        return \"Error: Movie ID must be an integer.\"\n",
    "\n",
    "    try:\n",
    "        movie_index = movie_ids.index(movie_id)\n",
    "    except ValueError:\n",
    "        return f\"Error: Movie ID {movie_id} not found in the dataset.\"\n",
    "\n",
    "    # Compute similarity scores\n",
    "    similarities = [\n",
    "        (i, combined_similarity(movie_index, i))\n",
    "        for i in range(len(movie_ids)) if i != movie_index\n",
    "    ]\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(f\"\\nRecommendations for Movie ID {movie_id} ({movie_titles[movie_index]}):\")\n",
    "    for i, (idx, sim) in enumerate(similarities[:top_n], 1):\n",
    "        print(f\"{i}. Movie: {movie_titles[idx]} (ID: {movie_ids[idx]}), Similarity: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e0303c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for 'The Dark Knight Rises' (index: 19065):\n",
      "1. Movie: The Dark Knight (ID: 155), Similarity: 0.4503\n",
      "2. Movie: Batman Begins (ID: 272), Similarity: 0.3405\n",
      "3. Movie: Batman: The Long Halloween, Part One (ID: 736073), Similarity: 0.3232\n",
      "4. Movie: Batman: The Long Halloween, Part Two (ID: 736074), Similarity: 0.3024\n",
      "5. Movie: Batman vs. Two-Face (ID: 464882), Similarity: 0.2858\n",
      "6. Movie: The Batman (ID: 414906), Similarity: 0.2651\n",
      "7. Movie: The Siege (ID: 9882), Similarity: 0.2562\n",
      "8. Movie: Class of 1984 (ID: 11564), Similarity: 0.2443\n",
      "9. Movie: The Bullet Train (ID: 47634), Similarity: 0.2397\n",
      "10. Movie: The Negotiator (ID: 9631), Similarity: 0.2391\n",
      "None\n",
      "Error: 'Non Existent Movie' not found in the dataset.\n",
      "Error: Movie title must be a string.\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "recommendations = get_recommendations_by_title('The Dark Knight Rises')  # Get recommendations for 'The Dark Knight Rises'\n",
    "print(recommendations)\n",
    "\n",
    "recommendations = get_recommendations_by_title('Non Existent Movie')  # Test with a movie not in the dataset\n",
    "print(recommendations)\n",
    "\n",
    "recommendations = get_recommendations_by_title(12345)  # Test with a non-string input\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e8322f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
