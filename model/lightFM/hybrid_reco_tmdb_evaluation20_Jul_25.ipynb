{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Usr1jvQgf84U"
      },
      "outputs": [],
      "source": [
        "# !pip install lightfm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "https://www.kaggle.com/code/niyamatalmass/lightfm-hybrid-recommendation-system \\\n",
        "\n",
        "https://making.lyst.com/lightfm/docs/home.html"
      ],
      "metadata": {
        "id": "jBak1pNMCKPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Help users discover movies they are most likely to enjoy based on thier unique taste"
      ],
      "metadata": {
        "id": "U6VdiUHwCcKk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQHn770FH1E5"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XVRZUVEw7KzK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "MOVIE_METADATA_PATH = \"movie_enriched_view.parquet\"\n",
        "USER_RATINGS_PATH = \"user_ratings_200users_30each.parquet\"\n",
        "movies_df = pd.read_parquet(MOVIE_METADATA_PATH)\n",
        "users_df = pd.read_parquet(USER_RATINGS_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L64CEFWMcpwA"
      },
      "source": [
        "##NOTE Generate numeric identifier: LightFM python only except numeric id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cNgk0i8uHykO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def generate_int_id(df: pd.DataFrame, col_name: str, new_col_name: str = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Convert a string/categorical column into unique integer IDs.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        Input DataFrame.\n",
        "    col_name : str\n",
        "        Name of the column to encode (e.g. 'user_id' or 'movie_id').\n",
        "    new_col_name : str, optional\n",
        "        Name of the new column to store integer IDs.\n",
        "        - If provided: a new column is created.\n",
        "        - If None: the original column is overwritten.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        DataFrame with the encoded integer column.\n",
        "    \"\"\"\n",
        "\n",
        "    # Factorize the column: assigns a unique integer to each unique value\n",
        "    # e.g. ['u1', 'u2', 'u1'] â†’ [0, 1, 0]\n",
        "    codes, uniques = pd.factorize(df[col_name])\n",
        "\n",
        "    # Determine where to store the result:\n",
        "    # - Use new_col_name if provided\n",
        "    # - Otherwise overwrite the original column\n",
        "    target_col = new_col_name if new_col_name is not None else col_name\n",
        "\n",
        "    # Store the encoded values in the target column\n",
        "    df[target_col] = codes.astype('int64')\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ND1MK95WZBoE"
      },
      "outputs": [],
      "source": [
        "users_df = generate_int_id(users_df, \"user_id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hiiBzveFNk8"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hVk6fZElKNk"
      },
      "source": [
        "Note that if we donâ€™t have all user and items ids at once, we can repeatedly call fit_partial to supply additional ids. In this case, we will use this capability to add some item feature mappings:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qDR1-zMbf3M"
      },
      "source": [
        "# Item Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3JRD6hlJO8z9"
      },
      "outputs": [],
      "source": [
        "def extract_item_feature_list(df, feature_columns):\n",
        "    \"\"\"\n",
        "    Extract unique lowercase feature values from selected metadata columns.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame containing movie metadata.\n",
        "    feature_columns : list of str\n",
        "        Column names to extract features from.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Set[str]\n",
        "        Set of all unique feature names (lowercased).\n",
        "    \"\"\"\n",
        "    movie_all_features = set()\n",
        "    for _, row in df.iterrows():\n",
        "        combined = []\n",
        "        for col in feature_columns:\n",
        "            combined.extend(str(row[col]).split(','))\n",
        "        cleaned = [f.strip().lower() for f in combined if f.strip()]\n",
        "        movie_all_features.update(cleaned)\n",
        "    return  list(movie_all_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UGmK12hCO9pw"
      },
      "outputs": [],
      "source": [
        "def build_item_feature_tuples(df, feature_columns):\n",
        "    \"\"\"\n",
        "    Build (movie_id, [features...]) tuples for LightFM item_features.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame containing movie metadata.\n",
        "    feature_columns : list of str\n",
        "        Columns to use for feature extraction.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    List[Tuple[int, List[str]]]\n",
        "        Tuples of movie_id and its feature list.\n",
        "    \"\"\"\n",
        "    tuples = []\n",
        "    for _, row in df.iterrows():\n",
        "        combined = []\n",
        "        for col in feature_columns:\n",
        "            combined.extend(str(row[col]).split(','))\n",
        "        cleaned = [f.strip().lower() for f in combined if f.strip()]\n",
        "        tuples.append((row['movie_id'], cleaned))\n",
        "    return tuples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mvmnWm9ARTCq"
      },
      "outputs": [],
      "source": [
        "from lightfm.data import Dataset\n",
        "\n",
        "# Step 1: Prepare dataset\n",
        "dataset = Dataset()\n",
        "dataset.fit(users_df['user_id'], movies_df['movie_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GiG4j0BkfnGc"
      },
      "outputs": [],
      "source": [
        "### TODO Rewrite Function\n",
        "# Step 2: Extract feature set and fit dataset\n",
        "feature_columns = ['genres', 'keywords']\n",
        "movie_all_features = extract_item_feature_list(movies_df, feature_columns)\n",
        "dataset.fit_partial(items=movies_df['movie_id'], item_features=movie_all_features)\n",
        "\n",
        "# TODO check build_item_features parameter format\n",
        "# Step 3: Build item_features matrix\n",
        "item_feature_tuples = build_item_feature_tuples(movies_df, feature_columns)\n",
        "item_features = dataset.build_item_features(item_feature_tuples)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Variable"
      ],
      "metadata": {
        "id": "xD2O6IEGdvC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "METHOD_STR=\"random_train_test_split\" # split_user_interactions_df random_train_test_split\n",
        "WEIGHT_METHOD_STR = \"default\" # default , condition_3, ratings\n"
      ],
      "metadata": {
        "id": "11nxpLxZdzl1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def split_user_interactions_df(df, user_col='user_id', test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Optimized version: split each user's interactions into train and test sets.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        DataFrame with user-item interactions.\n",
        "    user_col : str\n",
        "        Column for user ID.\n",
        "    test_size : float\n",
        "        Fraction of each user's data to put into test.\n",
        "    random_state : int\n",
        "        Random seed for reproducibility.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    train_df : pd.DataFrame\n",
        "    test_df : pd.DataFrame\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(random_state)\n",
        "\n",
        "    # Assign a row number within each user group\n",
        "    df = df.copy()\n",
        "    df['_row_id'] = df.groupby(user_col).cumcount()\n",
        "\n",
        "    # Count interactions per user\n",
        "    user_counts = df.groupby(user_col)['_row_id'].max() + 1\n",
        "\n",
        "    test_rows = []\n",
        "    for user_id, count in user_counts.items():\n",
        "        if count < 2:\n",
        "            continue\n",
        "        test_size_u = max(1, int(count * test_size))\n",
        "        test_indices = rng.choice(count, size=test_size_u, replace=False)\n",
        "        test_rows.extend(df[(df[user_col] == user_id) & (df['_row_id'].isin(test_indices))].index)\n",
        "\n",
        "    test_df = df.loc[test_rows].drop(columns=['_row_id'])\n",
        "    train_df = df.drop(index=test_rows).drop(columns=['_row_id'])\n",
        "\n",
        "    return train_df.reset_index(drop=True), test_df.reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "1vsHpUQTO7J-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightfm.cross_validation import random_train_test_split\n",
        "\n",
        "def train_test_split_method_return_interaction(\n",
        "    method_str=None,\n",
        "    weight_method_str=None,\n",
        "    df=None,\n",
        "    user_col=\"user_id\",\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    dataset=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Split interactions and weights using selected strategy.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    method_str : str\n",
        "        Splitting strategy, one of [\"split_user_interactions_df\", \"random_train_test_split\"].\n",
        "    weight_method_str : str\n",
        "        Weighting strategy, one of [\"default\", \"ratings\", \"condition_<rating_threshold>\"].\n",
        "    df : pd.DataFrame\n",
        "        DataFrame with user_id, movie_id, rating.\n",
        "    user_col : str\n",
        "        Column for user IDs (default \"user_id\").\n",
        "    test_size : float\n",
        "        Proportion for test split.\n",
        "    random_state : int\n",
        "        Random seed.\n",
        "    dataset : lightfm.data.Dataset\n",
        "        LightFM dataset object used for building interactions.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    method_str, train_interactions, test_interactions, train_weights, test_weights\n",
        "    \"\"\"\n",
        "\n",
        "    def build_interactions_by_weight(df, strategy, dataset):\n",
        "        if strategy == \"default\":\n",
        "            return dataset.build_interactions([\n",
        "                (u, i, 1.0)\n",
        "                for u, i, r in zip(df[\"user_id\"], df[\"movie_id\"], df[\"rating\"])\n",
        "            ])\n",
        "        elif strategy == \"ratings\":\n",
        "            return dataset.build_interactions([\n",
        "                (u, i, r)\n",
        "                for u, i, r in zip(df[\"user_id\"], df[\"movie_id\"], df[\"rating\"])\n",
        "            ])\n",
        "        elif str(strategy).startswith(\"condition_\"):\n",
        "            threshold = int(strategy.split(\"_\")[1])\n",
        "            return dataset.build_interactions([\n",
        "                (u, i, 1.0 if r >= threshold else 0.0)\n",
        "                for u, i, r in zip(df[\"user_id\"], df[\"movie_id\"], df[\"rating\"])\n",
        "            ])\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid weight_method_str: {strategy}\")\n",
        "\n",
        "    if method_str == \"split_user_interactions_df\":\n",
        "        train_df, test_df = split_user_interactions_df(\n",
        "            df=df, user_col=user_col, test_size=test_size, random_state=random_state\n",
        "        )\n",
        "\n",
        "        train_interactions, train_weights = build_interactions_by_weight(train_df, weight_method_str, dataset)\n",
        "        test_interactions, test_weights = build_interactions_by_weight(test_df, weight_method_str, dataset)\n",
        "\n",
        "    elif method_str == \"random_train_test_split\":\n",
        "        full_interactions, full_weights = build_interactions_by_weight(df, weight_method_str, dataset)\n",
        "\n",
        "        train_interactions, test_interactions = random_train_test_split(\n",
        "            full_interactions, test_percentage=test_size, random_state=random_state\n",
        "        )\n",
        "        train_weights, test_weights = random_train_test_split(\n",
        "            full_weights, test_percentage=test_size, random_state=random_state\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid method_str: {method_str}\")\n",
        "\n",
        "    return method_str, train_interactions, test_interactions, train_weights, test_weights\n"
      ],
      "metadata": {
        "id": "HR_64h1eRWZO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "method_str, train_interactions, test_interactions, train_weights, test_weights = \\\n",
        "    train_test_split_method_return_interaction(\n",
        "        method_str=METHOD_STR, # \"split_user_interactions_df\" \"random_train_test_split\"\n",
        "        weight_method_str=WEIGHT_METHOD_STR, #default, ratings, condition_3\n",
        "        df=users_df,\n",
        "        user_col=\"user_id\",\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        dataset=dataset\n",
        "    )"
      ],
      "metadata": {
        "id": "0S9M7lQHTR58"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EPOCHS = 10"
      ],
      "metadata": {
        "id": "_7j-khdNeHHt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter\n"
      ],
      "metadata": {
        "id": "LSvylILVeSE-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q6ar8Nblf_qW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOSS_FUNCTION = \"warp\" # warp , bpr, logistic\n",
        "EPOCHS = 100\n",
        "L_RATE = 0.05\n",
        "NO_COM = 30\n",
        "MAX_SAM = 30\n"
      ],
      "metadata": {
        "id": "Tb2W48fmeWIX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHLdH6xir0o1",
        "outputId": "1f5a6fde-ff4a-4044-fd2f-77be8f56b3f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7864c49f5d10>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "from lightfm import LightFM\n",
        "\n",
        "# 3. Train the model using only the training interactions and corresponding weights\n",
        "model = LightFM(\n",
        "    loss=LOSS_FUNCTION, # warp , bpr, logistic\n",
        "    learning_rate=L_RATE,\n",
        "    no_components=NO_COM,\n",
        "    max_sampled=MAX_SAM,\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    interactions=train_interactions,\n",
        "    item_features=item_features,\n",
        "    sample_weight=train_weights,\n",
        "    epochs=EPOCHS,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ydu1ALhQz2l"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# Evaluation\"\"\"\n",
        "from lightfm.evaluation import precision_at_k, recall_at_k, auc_score\n",
        "\n",
        "def evaluate_model(model, interactions, k_list, item_features=None, train_interactions=None, split_name=\"TRAIN\"):\n",
        "    precision_scores = {}\n",
        "    recall_scores = {}\n",
        "\n",
        "    for k in k_list:\n",
        "        precision = precision_at_k(\n",
        "            model, interactions, train_interactions=train_interactions,\n",
        "            item_features=item_features, k=k\n",
        "        ).mean()\n",
        "        recall = recall_at_k(\n",
        "            model, interactions, train_interactions=train_interactions,\n",
        "            item_features=item_features, k=k\n",
        "        ).mean()\n",
        "\n",
        "        precision_scores[k] = precision\n",
        "        recall_scores[k] = recall\n",
        "\n",
        "    auc = auc_score(\n",
        "        model, interactions, train_interactions=train_interactions,\n",
        "        item_features=item_features\n",
        "    ).mean()\n",
        "\n",
        "    # Print section\n",
        "    print(f\"{split_name} Evaluation\")\n",
        "    for k in k_list:\n",
        "        print(f\"Precision@{k}: {precision_scores[k]:.4f}\")\n",
        "        print(f\"Recall@{k}: {recall_scores[k]:.4f}\\n\")\n",
        "    print(f\"AUC: {auc:.4f}\\n\")\n",
        "\n",
        "    return precision_scores, recall_scores, auc\n"
      ],
      "metadata": {
        "id": "FDArn9eY_isT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary"
      ],
      "metadata": {
        "id": "wcNN74_tUJc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set k values\n",
        "k_values = [3, 5, 10]\n",
        "\n",
        "\"\"\"# Summary\"\"\"\n",
        "print(\"Summary\")\n",
        "print(f\"Train Test Method: {METHOD_STR}\")\n",
        "print(f\"Weight Method: {WEIGHT_METHOD_STR}\")\n",
        "print(f\"Loss Function: {LOSS_FUNCTION}\")\n",
        "print(\"Epochs:\", EPOCHS)\n",
        "print(\"Learning rate:\", L_RATE)\n",
        "print(\"No. components:\", NO_COM)\n",
        "print(\"Max sampled:\", MAX_SAM)\n",
        "print()\n",
        "\n",
        "# Evaluate on train\n",
        "train_precision_scores, train_recall_scores, train_auc = evaluate_model(\n",
        "    model, train_interactions, k_values, item_features=item_features, split_name=\"TRAIN\"\n",
        ")\n",
        "\n",
        "# Evaluate on test\n",
        "test_precision_scores, test_recall_scores, test_auc = evaluate_model(\n",
        "    model, test_interactions, k_values, item_features=item_features,\n",
        "    train_interactions=train_interactions, split_name=\"TEST\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqwhJNcK_iV8",
        "outputId": "6b3035ef-97e7-4c35-b009-3f35488540fe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary\n",
            "Train Test Method: random_train_test_split\n",
            "Weight Method: default\n",
            "Loss Function: warp\n",
            "Epochs: 100\n",
            "Learning rate: 0.05\n",
            "No. components: 30\n",
            "Max sampled: 30\n",
            "\n",
            "TRAIN Evaluation\n",
            "Precision@3: 0.6717\n",
            "Recall@3: 0.0845\n",
            "\n",
            "Precision@5: 0.6570\n",
            "Recall@5: 0.1378\n",
            "\n",
            "Precision@10: 0.6185\n",
            "Recall@10: 0.2588\n",
            "\n",
            "AUC: 0.9999\n",
            "\n",
            "TEST Evaluation\n",
            "Precision@3: 0.2667\n",
            "Recall@3: 0.1341\n",
            "\n",
            "Precision@5: 0.2240\n",
            "Recall@5: 0.1859\n",
            "\n",
            "Precision@10: 0.1755\n",
            "Recall@10: 0.2977\n",
            "\n",
            "AUC: 0.9720\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommend"
      ],
      "metadata": {
        "id": "1AP6qjFBB-Ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sample_recommendation(model, dataset, interactions, item_features,\n",
        "                          user_ids, movies_df, top_n=5):\n",
        "    \"\"\"\n",
        "    Show known positives and top-N recommendations with scores for each user.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained LightFM model\n",
        "    - dataset: LightFM dataset object (needed to extract mappings)\n",
        "    - interactions: Sparse interaction matrix\n",
        "    - item_features: Sparse matrix of item metadata\n",
        "    - user_ids: List of actual user IDs (external IDs)\n",
        "    - movies_df: DataFrame with 'movie_id' and 'title'\n",
        "    - top_n: Number of recommendations to return per user\n",
        "\n",
        "    Returns:\n",
        "    - Dict with user_id as key and list of top-N recommendations as value\n",
        "    \"\"\"\n",
        "    user_id_map, _, item_id_map, _ = dataset.mapping()\n",
        "    item_id_inv_map = {v: k for k, v in item_id_map.items()}\n",
        "\n",
        "    def get_seen_movie_ids(uidx):\n",
        "        seen_indices = interactions.tocsr()[uidx].indices\n",
        "        return [item_id_inv_map[i] for i in seen_indices]\n",
        "\n",
        "    def get_movie_info(movie_id):\n",
        "        row = movies_df[movies_df['movie_id'] == movie_id]\n",
        "        if row.empty:\n",
        "            return {\"title\": \"Unknown\", \"genres\": \"N/A\", \"keywords\": \"N/A\"}\n",
        "        row = row.iloc[0]\n",
        "        return {\n",
        "            \"title\": row.get(\"title\", \"Unknown\"),\n",
        "            \"genres\": row.get(\"genres\", \"N/A\"),\n",
        "            \"keywords\": row.get(\"keywords\", \"N/A\")\n",
        "        }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for user_id in user_ids:\n",
        "        if user_id not in user_id_map:\n",
        "            print(f\"User {user_id} not found in training set.\\n\")\n",
        "            continue\n",
        "\n",
        "        uidx = user_id_map[user_id]\n",
        "        n_items = interactions.shape[1]\n",
        "\n",
        "        seen_movie_ids = get_seen_movie_ids(uidx)\n",
        "        known_titles = movies_df[movies_df['movie_id'].isin(seen_movie_ids)]['title'].tolist()\n",
        "\n",
        "        scores = model.predict(uidx, np.arange(n_items), item_features=item_features)\n",
        "        top_indices = np.argsort(-scores)[:top_n]\n",
        "\n",
        "        # === DEBUG ===\n",
        "        print(f\"\\nðŸŽ¯ User: {user_id}\")\n",
        "        print(\"âœ… Known positives:\")\n",
        "        for movie_id in seen_movie_ids[:min(len(seen_movie_ids), 10)]:\n",
        "            info = get_movie_info(movie_id)\n",
        "            print(f\"   â€¢ {info['title']}\")\n",
        "            print(f\"     Genres: {info['genres']}\")\n",
        "            print(f\"     Keywords: {info['keywords']}\")\n",
        "\n",
        "        print(f\"ðŸ”® Top {top_n} Recommendations:\")\n",
        "        user_recommendations = []\n",
        "        for idx in top_indices:\n",
        "            movie_id = item_id_inv_map[idx]\n",
        "            info = get_movie_info(movie_id)\n",
        "            score = round(scores[idx], 4)\n",
        "\n",
        "            print(f\"   â€¢ {info['title']} (score: {score})\")\n",
        "            print(f\"     Genres: {info['genres']}\")\n",
        "            print(f\"     Keywords: {info['keywords']}\")\n",
        "\n",
        "            user_recommendations.append({\n",
        "                \"movie_id\": movie_id,\n",
        "                \"title\": info[\"title\"],\n",
        "                \"genres\": info[\"genres\"],\n",
        "                \"keywords\": info[\"keywords\"],\n",
        "                \"score\": score\n",
        "            })\n",
        "\n",
        "        results[user_id] = user_recommendations\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "wucYScyWB3x2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_recommendation(\n",
        "    model=model,\n",
        "    dataset=dataset,\n",
        "    interactions=train_interactions,\n",
        "    item_features=item_features,\n",
        "    user_ids=[0],\n",
        "    movies_df=movies_df,\n",
        "    top_n=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LCNSWqwB5fu",
        "outputId": "c2fed29c-4fa7-48ce-b271-f4e368f217d2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸŽ¯ User: 0\n",
            "âœ… Known positives:\n",
            "   â€¢ Hedwig and the Angry Inch\n",
            "     Genres: Drama, Music, Comedy\n",
            "     Keywords: lgbt in the military, self identity, glam rock, singer, child molestation, transsexuality, restaurant chain, nonbinary director, military brat, lgbt, rock odyssey, transvestism, theatrical manager\n",
            "   â€¢ (Nie)znajomi\n",
            "     Genres: Drama, Comedy\n",
            "     Keywords: man woman relationship, father daughter relationship, husband wife relationship, lgbt, mother daughter relationship, friendship, remake\n",
            "   â€¢ Charlotte's Web\n",
            "     Genres: Drama, Family, Animation, Music, Comedy\n",
            "     Keywords: spider web, talking pig, musical, anthropomorphism, friendship, cartoon spider\n",
            "   â€¢ Sidekicks\n",
            "     Genres: Adventure, Drama, Family, Action\n",
            "     Keywords: asthmatic, gym instructor, martial arts training, computer programmer, bully, nunchaku, parent teacher romance, student mentor relationship, training-montage, daydreaming, martial arts, martial arts tournament, chinese restaurant, karate\n",
            "   â€¢ Lo Steinway\n",
            "     Genres: Drama, War, History, Animation\n",
            "     Keywords: truce, great war, piano\n",
            "   â€¢ Emperor Meiji and General Nogi\n",
            "     Genres: Drama, War, History\n",
            "     Keywords: japan, history of japan, russo-japanese war, imperial japan\n",
            "   â€¢ Private Detective DOBU 4: The Mysterious Kite Murders Case\n",
            "     Genres: Drama, History, Action\n",
            "     Keywords: jidaigeki\n",
            "   â€¢ The Notorious Bored Samurai 3\n",
            "     Genres: Drama, History, Action\n",
            "     Keywords: jidaigeki\n",
            "   â€¢ Tatara Samurai\n",
            "     Genres: Drama, War, History, Comedy, Action\n",
            "     Keywords: samurai, chanbara\n",
            "   â€¢ The Ode to Joy\n",
            "     Genres: Drama, War, History, Music\n",
            "     Keywords: japan, germany\n",
            "ðŸ”® Top 10 Recommendations:\n",
            "   â€¢ Emperor Meiji and General Nogi (score: 2.112499952316284)\n",
            "     Genres: Drama, War, History\n",
            "     Keywords: japan, history of japan, russo-japanese war, imperial japan\n",
            "   â€¢ Hotel Very Welcome (score: 2.0048999786376953)\n",
            "     Genres: Drama\n",
            "     Keywords: travel, backpacker, thailand, goa, relationship, woman director, sense of life\n",
            "   â€¢ The Notorious Bored Samurai 3 (score: 1.9788999557495117)\n",
            "     Genres: Drama, History, Action\n",
            "     Keywords: jidaigeki\n",
            "   â€¢ Lo Steinway (score: 1.9559999704360962)\n",
            "     Genres: Drama, War, History, Animation\n",
            "     Keywords: truce, great war, piano\n",
            "   â€¢ Hedwig and the Angry Inch (score: 1.9466999769210815)\n",
            "     Genres: Drama, Music, Comedy\n",
            "     Keywords: lgbt in the military, self identity, glam rock, singer, child molestation, transsexuality, restaurant chain, nonbinary director, military brat, lgbt, rock odyssey, transvestism, theatrical manager\n",
            "   â€¢ Emperor Meiji and the Great Russo-Japanese War (score: 1.9391000270843506)\n",
            "     Genres: Drama, War, History\n",
            "     Keywords: japan, history of japan, russo-japanese war, imperial japan\n",
            "   â€¢ Charlotte's Web (score: 1.9313000440597534)\n",
            "     Genres: Drama, Family, Animation, Music, Comedy\n",
            "     Keywords: spider web, talking pig, musical, anthropomorphism, friendship, cartoon spider\n",
            "   â€¢ Lady Maiko (score: 1.90910005569458)\n",
            "     Genres: Drama, Music, Comedy\n",
            "     Keywords: japan, geisha, coming of age, kyoto, maiko\n",
            "   â€¢ Hot Rhythm (score: 1.8955999612808228)\n",
            "     Genres: Romance, War, Music, Comedy\n",
            "     Keywords: record company, singer, radio, contract\n",
            "   â€¢ The Samurai in Autumn (score: 1.8544000387191772)\n",
            "     Genres: Drama, Comedy, Action\n",
            "     Keywords: samurai, sports, fighter, romance, karate\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: [{'movie_id': 365507,\n",
              "   'title': 'Emperor Meiji and General Nogi',\n",
              "   'genres': 'Drama, War, History',\n",
              "   'keywords': 'japan, history of japan, russo-japanese war, imperial japan',\n",
              "   'score': np.float32(2.1125)},\n",
              "  {'movie_id': 4344,\n",
              "   'title': 'Hotel Very Welcome',\n",
              "   'genres': 'Drama',\n",
              "   'keywords': 'travel, backpacker, thailand, goa, relationship, woman director, sense of life',\n",
              "   'score': np.float32(2.0049)},\n",
              "  {'movie_id': 1292715,\n",
              "   'title': 'The Notorious Bored Samurai 3',\n",
              "   'genres': 'Drama, History, Action',\n",
              "   'keywords': 'jidaigeki',\n",
              "   'score': np.float32(1.9789)},\n",
              "  {'movie_id': 707588,\n",
              "   'title': 'Lo Steinway',\n",
              "   'genres': 'Drama, War, History, Animation',\n",
              "   'keywords': 'truce, great war, piano',\n",
              "   'score': np.float32(1.956)},\n",
              "  {'movie_id': 13403,\n",
              "   'title': 'Hedwig and the Angry Inch',\n",
              "   'genres': 'Drama, Music, Comedy',\n",
              "   'keywords': 'lgbt in the military, self identity, glam rock, singer, child molestation, transsexuality, restaurant chain, nonbinary director, military brat, lgbt, rock odyssey, transvestism, theatrical manager',\n",
              "   'score': np.float32(1.9467)},\n",
              "  {'movie_id': 354577,\n",
              "   'title': 'Emperor Meiji and the Great Russo-Japanese War',\n",
              "   'genres': 'Drama, War, History',\n",
              "   'keywords': 'japan, history of japan, russo-japanese war, imperial japan',\n",
              "   'score': np.float32(1.9391)},\n",
              "  {'movie_id': 15171,\n",
              "   'title': \"Charlotte's Web\",\n",
              "   'genres': 'Drama, Family, Animation, Music, Comedy',\n",
              "   'keywords': 'spider web, talking pig, musical, anthropomorphism, friendship, cartoon spider',\n",
              "   'score': np.float32(1.9313)},\n",
              "  {'movie_id': 295709,\n",
              "   'title': 'Lady Maiko',\n",
              "   'genres': 'Drama, Music, Comedy',\n",
              "   'keywords': 'japan, geisha, coming of age, kyoto, maiko',\n",
              "   'score': np.float32(1.9091)},\n",
              "  {'movie_id': 88022,\n",
              "   'title': 'Hot Rhythm',\n",
              "   'genres': 'Romance, War, Music, Comedy',\n",
              "   'keywords': 'record company, singer, radio, contract',\n",
              "   'score': np.float32(1.8956)},\n",
              "  {'movie_id': 419307,\n",
              "   'title': 'The Samurai in Autumn',\n",
              "   'genres': 'Drama, Comedy, Action',\n",
              "   'keywords': 'samurai, sports, fighter, romance, karate',\n",
              "   'score': np.float32(1.8544)}]}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ScXgX3ttB6jD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}